{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/varunnegandhi/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           SentimentText Sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n",
      "                                           SentimentText Sentiment\n",
      "0      first think another Disney movie, might good, ...  positive\n",
      "1      Put aside Dr. House repeat missed, Desperate H...  negative\n",
      "2      big fan Stephen King's work, film made even gr...  positive\n",
      "3      watched horrid thing TV. Needless say one movi...  negative\n",
      "4      truly enjoyed film. acting terrific plot. Jeff...  positive\n",
      "...                                                  ...       ...\n",
      "24996  course reading review seen film already. 'Raja...  positive\n",
      "24997  read \"There's Girl Soup\" came Peter Sellers's ...  negative\n",
      "24998  film quite boring. snippets naked flesh tossed...  negative\n",
      "24999  Although film somewhat filled eighties cheese ...  positive\n",
      "25000  It's not even 5 days since i purchased this pr...  negative\n",
      "\n",
      "[25001 rows x 2 columns]\n",
      "                                           SentimentText Sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"Training_Data.csv\")\n",
    "print(train)\n",
    "test = pd.read_csv(\"Test_Data.csv\",encoding=\"latin-1\")\n",
    "test['Sentiment']=test[\"Sentiment\"].map({1:'positive' , 0: 'negative'})\n",
    "print(test)\n",
    "#data = pd.concat([train,test])\n",
    "data = train\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" \n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03087823 -0.06816969  0.00478594 ... -0.04904244  0.00312513\n",
      "   0.04500568]\n",
      " [ 0.024796   -0.03751242 -0.00023623 ... -0.01052065 -0.01016857\n",
      "  -0.01321065]\n",
      " [ 0.02137806  0.05823477 -0.01021961 ...  0.06828433 -0.01064305\n",
      "   0.072465  ]\n",
      " ...\n",
      " [-0.0076001   0.01783323 -0.00141936 ... -0.05320873 -0.02816549\n",
      "   0.06544039]\n",
      " [-0.01944417 -0.03632438 -0.00631774 ... -0.02648013  0.00287605\n",
      "   0.03750989]\n",
      " [ 0.06568789  0.01749829 -0.055237   ... -0.02553775 -0.04536348\n",
      "   0.01368993]]\n"
     ]
    }
   ],
   "source": [
    "sentence_list = list(data['SentimentText'])\n",
    "print(sentence_list)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  sentence_embeddings = session.run(embed(sentence_list))\n",
    "\n",
    "print(np.array(sentence_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 50000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(np.array(sentence_embeddings))\n",
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [SentimentText, Sentiment]\n",
      "Index: []\n",
      "50000\n",
      "[0.30699748 0.50442725 0.65838945 ... 0.49659336 0.64077044 0.6159339 ]\n",
      "[[-0.02724895  0.00743809 -0.00618643 ... -0.00343892  0.00357993\n",
      "   0.03877556]\n",
      " [ 0.01704155  0.04490056 -0.00240944 ... -0.03973788 -0.01330681\n",
      "   0.00876388]]\n",
      "(2, 512)\n",
      "[    5 30495]\n",
      "[0.9999999 0.8495669]\n",
      "Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. Paul Lukas' performance brings tears to my eyes, and Bette Davis, in one of her very few truly sympathetic roles, is a delight. The kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.\n",
      "This movie is brilliant in every way. It touches on the complexities of loving relationships in a meaningful way, but never lectures. The script never condescends toward any character, not even the hapless Johnny. It also and benefits from spot-on direction, production design, casting, and performances. The fact that Cher is so perfect in the film and is more unlike \"Cher\" than she has ever been is a wonder to me. I watch Moonstruck at least once a year and I just viewed it again this Christmas eve with my 16 year old twin daughters and they loved it as well. It has something for everyone with a heart and leaves you filled with joy in the end.\n",
      "Required matrix:\n",
      "[array([[-0.02724895,  0.00743809, -0.00618643, ..., -0.00343892,\n",
      "         0.00357993,  0.03877556],\n",
      "       [ 0.01704155,  0.04490056, -0.00240944, ..., -0.03973788,\n",
      "        -0.01330681,  0.00876388]], dtype=float32)]\n",
      "Shape: (1, 2, 512)\n"
     ]
    }
   ],
   "source": [
    "col_names = list(data.columns)\n",
    "col_names\n",
    "df = pd.DataFrame(columns = col_names)\n",
    "print(df)\n",
    "\n",
    "neighbors = []\n",
    "print(len(sentence_list))\n",
    "#for n in range(len(sentence_list)):\n",
    "    #print(n)\n",
    "sentence = sentence_list[5]\n",
    "i = sentence_list.index(sentence)\n",
    "row = np.array(similarity[i,:])\n",
    "print(row)\n",
    "sentence_index = row.argsort()[-2:][::-1]\n",
    "print(sentence_embeddings[sentence_index])\n",
    "print(sentence_embeddings[sentence_index].shape)\n",
    "print(sentence_index)\n",
    "print(row[sentence_index])\n",
    "print(*[sentence_list[i] for i in sentence_index], sep=\"\\n\")\n",
    "neighbors.append(sentence_embeddings[sentence_index])\n",
    "print(\"Required matrix:\")\n",
    "print(neighbors)\n",
    "print(\"Shape:\", np.array(neighbors).shape)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n",
      "(50000, 1)\n",
      "(50000, 3)\n",
      "                                        Embedding_Matrix  \\\n",
      "0      [[0.030878235, -0.06816969, 0.004785944, -0.05...   \n",
      "1      [[0.024796002, -0.037512418, -0.0002362301, -0...   \n",
      "2      [[0.021378059, 0.05823477, -0.010219607, -0.06...   \n",
      "3      [[-0.0059442, -0.057756796, -0.03130618, -0.02...   \n",
      "4      [[0.050902136, 0.04202257, -0.014997388, -0.06...   \n",
      "...                                                  ...   \n",
      "49995  [[-0.0045723096, 0.015551986, -0.022343015, -0...   \n",
      "49996  [[0.019559477, 0.0016787908, -0.015686644, -0....   \n",
      "49997  [[-0.007600099, 0.017833227, -0.0014193594, 0....   \n",
      "49998  [[-0.019444171, -0.03632438, -0.006317741, -0....   \n",
      "49999  [[0.065687895, 0.017498286, -0.055237003, -0.0...   \n",
      "\n",
      "                                           SentimentText Sentiment  \n",
      "0      One of the other reviewers has mentioned that ...  positive  \n",
      "1      A wonderful little production. <br /><br />The...  positive  \n",
      "2      I thought this was a wonderful way to spend ti...  positive  \n",
      "3      Basically there's a family where a little boy ...  negative  \n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive  \n",
      "...                                                  ...       ...  \n",
      "49995  I thought this movie did a down right good job...  positive  \n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative  \n",
      "49997  I am a Catholic taught in parochial elementary...  negative  \n",
      "49998  I'm going to have to disagree with the previou...  negative  \n",
      "49999  No one expects the Star Trek movies to be high...  negative  \n",
      "\n",
      "[50000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.DataFrame([neighbors]).transpose()\n",
    "print(data.shape)\n",
    "print(data2.shape)\n",
    "data2['SentimentText']=data['SentimentText']\n",
    "data2['Sentiment']=data['Sentiment']\n",
    "print(data2.shape)\n",
    "data2.rename(columns = {0:'Embedding_Matrix'}, inplace=True)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data2['Sentiment']\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_enc = encode(le, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 512)\n",
      "23990    [[-0.043813415, -0.0053389403, -0.032010645, -...\n",
      "8729     [[0.018371582, -0.011922709, 0.0033760297, -0....\n",
      "3451     [[-0.010972981, -0.01482286, -0.00017860503, -...\n",
      "2628     [[0.022037432, 0.030444149, -0.008778872, -0.0...\n",
      "38352    [[0.05383027, 0.024601217, -0.06429972, -0.040...\n",
      "                               ...                        \n",
      "11284    [[0.05198604, -0.021432154, -0.0005987687, -0....\n",
      "44732    [[-0.009684506, -0.03869877, -0.032634277, -0....\n",
      "38158    [[-0.0022769442, -0.03521671, -0.031315487, -0...\n",
      "860      [[-0.00472308, -0.01658315, 0.02326638, -0.080...\n",
      "15795    [[0.057155646, -0.04065958, -0.044187304, -0.0...\n",
      "Name: Embedding_Matrix, Length: 33500, dtype: object\n",
      "(33500,)\n"
     ]
    }
   ],
   "source": [
    "print(data2['Embedding_Matrix'][0].shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data2['Embedding_Matrix'], y_enc, test_size=0.33, random_state=42)\n",
    "print(x_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 23, 510, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 11, 255, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 9, 253, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 126, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 2, 124, 80)        46160     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 1, 62, 80)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1, 62, 80)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4960)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 300)               1488300   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 1,644,178\n",
      "Trainable params: 1,644,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "model = keras.models.Sequential()\n",
    "model.add(Convolution2D(filters=32,kernel_size=3,input_shape=(25,512,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(filters=64,kernel_size=3))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(filters=80,kernel_size=3))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33500, 25, 512, 1)\n",
      "(512, 1)\n",
      "Train on 26800 samples, validate on 6700 samples\n",
      "Epoch 1/10\n",
      "26800/26800 [==============================] - 544s 20ms/step - loss: 0.5638 - acc: 0.7042 - val_loss: 0.4478 - val_acc: 0.8007\n",
      "Epoch 2/10\n",
      "26800/26800 [==============================] - 544s 20ms/step - loss: 0.4412 - acc: 0.7973 - val_loss: 0.4165 - val_acc: 0.8143\n",
      "Epoch 3/10\n",
      "26800/26800 [==============================] - 510s 19ms/step - loss: 0.4225 - acc: 0.8096 - val_loss: 0.4078 - val_acc: 0.8200\n",
      "Epoch 4/10\n",
      "26800/26800 [==============================] - 528s 20ms/step - loss: 0.4113 - acc: 0.8153 - val_loss: 0.3968 - val_acc: 0.8234\n",
      "Epoch 5/10\n",
      "26800/26800 [==============================] - 524s 20ms/step - loss: 0.4064 - acc: 0.8170 - val_loss: 0.3925 - val_acc: 0.8237\n",
      "Epoch 6/10\n",
      "26800/26800 [==============================] - 551s 21ms/step - loss: 0.3961 - acc: 0.8219 - val_loss: 0.3912 - val_acc: 0.8281\n",
      "Epoch 7/10\n",
      "26800/26800 [==============================] - 541s 20ms/step - loss: 0.3901 - acc: 0.8262 - val_loss: 0.3881 - val_acc: 0.8304\n",
      "Epoch 8/10\n",
      "26800/26800 [==============================] - 546s 20ms/step - loss: 0.3845 - acc: 0.8275 - val_loss: 0.3826 - val_acc: 0.8294\n",
      "Epoch 9/10\n",
      "26800/26800 [==============================] - 27791s 1s/step - loss: 0.3824 - acc: 0.8291 - val_loss: 0.3813 - val_acc: 0.8318\n",
      "Epoch 10/10\n",
      "26800/26800 [==============================] - 508s 19ms/step - loss: 0.3778 - acc: 0.8318 - val_loss: 0.3804 - val_acc: 0.8309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25f29e7f28>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array(list(x_train))\n",
    "x_train = x_train.reshape([-1,25, 512,1])\n",
    "#print(x_train)\n",
    "print(x_train.shape)\n",
    "print(x_train[860][0].shape)\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=1000, epochs=10, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16500, 25, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(list(x_test))\n",
    "x_test = x_test.reshape([-1,25, 512,1])\n",
    "#print(x_train)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48863938 0.5113605 ]\n",
      " [0.04703605 0.95296395]\n",
      " [0.8830941  0.11690585]\n",
      " ...\n",
      " [0.01500397 0.98499596]\n",
      " [0.09716868 0.9028314 ]\n",
      " [0.7744955  0.2255045 ]]\n"
     ]
    }
   ],
   "source": [
    "predicts = model.predict(x_test, batch_size=1000)\n",
    "print(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'positive' 'negative' ... 'positive' 'positive' 'negative']\n",
      "object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.82      8208\n",
      "    positive       0.81      0.88      0.84      8292\n",
      "\n",
      "    accuracy                           0.83     16500\n",
      "   macro avg       0.84      0.83      0.83     16500\n",
      "weighted avg       0.84      0.83      0.83     16500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test1 = decode(le, y_test)\n",
    "y_preds = decode(le, predicts)\n",
    "print(y_preds)\n",
    "print(y_test1.dtype)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(list(y_test1), list(y_preds))\n",
    "print(metrics.classification_report(list(y_test1), list(y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-30cb9712deaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'negative'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-sessions/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame(sentence_embeddings)\n",
    "new_data['Sentiment']=data['Sentiment']\n",
    "new_data\n",
    "X_train1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>keys</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.dateAdded</th>\n",
       "      <th>reviews.dateSeen</th>\n",
       "      <th>reviews.didPurchase</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <th>reviews.id</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>410</td>\n",
       "      <td>326</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>269</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>402</td>\n",
       "      <td>339</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>280</td>\n",
       "      <td>402</td>\n",
       "      <td>0</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1499</td>\n",
       "      <td>1289</td>\n",
       "      <td>1499</td>\n",
       "      <td>1499</td>\n",
       "      <td>1499</td>\n",
       "      <td>1499</td>\n",
       "      <td>1499</td>\n",
       "      <td>1499</td>\n",
       "      <td>1081</td>\n",
       "      <td>1499</td>\n",
       "      <td>0</td>\n",
       "      <td>1470</td>\n",
       "      <td>0</td>\n",
       "      <td>1475</td>\n",
       "      <td>1499</td>\n",
       "      <td>1499</td>\n",
       "      <td>1499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>8541</td>\n",
       "      <td>7220</td>\n",
       "      <td>8540</td>\n",
       "      <td>8541</td>\n",
       "      <td>8541</td>\n",
       "      <td>8541</td>\n",
       "      <td>8541</td>\n",
       "      <td>8531</td>\n",
       "      <td>6191</td>\n",
       "      <td>8541</td>\n",
       "      <td>0</td>\n",
       "      <td>8469</td>\n",
       "      <td>0</td>\n",
       "      <td>8480</td>\n",
       "      <td>8541</td>\n",
       "      <td>8541</td>\n",
       "      <td>8541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>23775</td>\n",
       "      <td>18694</td>\n",
       "      <td>23774</td>\n",
       "      <td>23775</td>\n",
       "      <td>23775</td>\n",
       "      <td>23775</td>\n",
       "      <td>23775</td>\n",
       "      <td>23756</td>\n",
       "      <td>16218</td>\n",
       "      <td>23775</td>\n",
       "      <td>1</td>\n",
       "      <td>23389</td>\n",
       "      <td>1</td>\n",
       "      <td>23413</td>\n",
       "      <td>23775</td>\n",
       "      <td>23773</td>\n",
       "      <td>23770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id   name  asins  brand  categories   keys  manufacturer  \\\n",
       "reviews.rating                                                                \n",
       "1.0               410    326    410    410         410    410           410   \n",
       "2.0               402    339    402    402         402    402           402   \n",
       "3.0              1499   1289   1499   1499        1499   1499          1499   \n",
       "4.0              8541   7220   8540   8541        8541   8541          8541   \n",
       "5.0             23775  18694  23774  23775       23775  23775         23775   \n",
       "\n",
       "                reviews.date  reviews.dateAdded  reviews.dateSeen  \\\n",
       "reviews.rating                                                      \n",
       "1.0                      410                269               410   \n",
       "2.0                      402                280               402   \n",
       "3.0                     1499               1081              1499   \n",
       "4.0                     8531               6191              8541   \n",
       "5.0                    23756              16218             23775   \n",
       "\n",
       "                reviews.didPurchase  reviews.doRecommend  reviews.id  \\\n",
       "reviews.rating                                                         \n",
       "1.0                               0                  356           0   \n",
       "2.0                               0                  382           0   \n",
       "3.0                               0                 1470           0   \n",
       "4.0                               0                 8469           0   \n",
       "5.0                               1                23389           1   \n",
       "\n",
       "                reviews.numHelpful  reviews.sourceURLs  reviews.text  \\\n",
       "reviews.rating                                                         \n",
       "1.0                            375                 410           410   \n",
       "2.0                            388                 402           402   \n",
       "3.0                           1475                1499          1499   \n",
       "4.0                           8480                8541          8541   \n",
       "5.0                          23413               23775         23773   \n",
       "\n",
       "                reviews.title  reviews.userCity  reviews.userProvince  \\\n",
       "reviews.rating                                                          \n",
       "1.0                       410                 0                     0   \n",
       "2.0                       402                 0                     0   \n",
       "3.0                      1499                 0                     0   \n",
       "4.0                      8541                 0                     0   \n",
       "5.0                     23770                 0                     0   \n",
       "\n",
       "                reviews.username  \n",
       "reviews.rating                    \n",
       "1.0                          410  \n",
       "2.0                          402  \n",
       "3.0                         1499  \n",
       "4.0                         8541  \n",
       "5.0                        23773  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Amazon-Product-Reviews.csv\")\n",
    "df.groupby('reviews.rating').count()[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
